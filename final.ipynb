{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T07:31:24.421547Z",
     "start_time": "2025-07-27T07:31:18.385699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sqlalchemy.testing.suite.test_reflection import metadata\n",
    "!pip install -qU pymupdf4llm Pillow langchain langchain-openai langchain-text-splitters langchain_community langchain-pymupdf4llm langgraph gradio ipywidgets"
   ],
   "id": "c78e2d9c10670167",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T07:31:24.805020Z",
     "start_time": "2025-07-27T07:31:24.791625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    raise \"OPENAI_API_KEY not set\"\n",
    "\n",
    "if not os.environ.get(\"LANGSMITH_API_KEY\"):\n",
    "    raise \"LANGSMITH_API_KEY not set\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"ai-final\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "PDF_FILE = \"EPAM-Reports-Results-for-Fourth-Quarter-and-Full-Year-2024_4.pdf\"\n",
    "\n",
    "IMAGES_FOLDER = './storage/images'\n",
    "TABLES_FOLDER = './storage/tables'\n",
    "\n",
    "IMAGES_SUMMARY_MODEL = \"gpt-4o-mini\"\n",
    "IMAGES_SUMMARY_PROMPT = \"Describe the image in detail. For context, the image is part of a PDF document\"\n",
    "\n",
    "TABLES_SUMMARY_MODEL = \"gpt-4o-mini\"\n",
    "TABLES_SUMMARY_PROMPT = \"Describe the image of the table in detail. For context, the image is part of a PDF document.\"\n",
    "\n",
    "LLM_MODEL = \"gpt-4o\"\n",
    "\n",
    "CHUNK_SIZE = 500\n",
    "CHUNK_OVERLAP = 0\n",
    "\n",
    "EMBEDDINGS_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "os.makedirs(IMAGES_FOLDER, exist_ok=True)\n",
    "os.makedirs(TABLES_FOLDER, exist_ok=True)\n"
   ],
   "id": "68117cbceef63d50",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T07:31:27.551303Z",
     "start_time": "2025-07-27T07:31:24.833980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import fitz\n",
    "import io\n",
    "from PIL import Image\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.documents import Document\n",
    "import pymupdf4llm\n",
    "import base64\n",
    "from IPython.display import Markdown\n",
    "from langchain.chat_models import init_chat_model\n",
    "import IPython.display\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "import json\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T07:31:27.576501Z",
     "start_time": "2025-07-27T07:31:27.569515Z"
    }
   },
   "cell_type": "code",
   "source": "doc: fitz.Document = fitz.open(PDF_FILE)",
   "id": "6474ceaaf1669b2d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T07:31:27.607837Z",
     "start_time": "2025-07-27T07:31:27.602440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def summarize_images(images: list[str], prompt_template: str, model) -> list[str]:\n",
    "    messages = [\n",
    "        (\n",
    "            \"user\",\n",
    "            [\n",
    "                {\"type\": \"text\", \"text\": prompt_template},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": \"data:image/png;base64,{image}\"},\n",
    "                },\n",
    "            ],\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "    chain = prompt | ChatOpenAI(model=model) | StrOutputParser()\n",
    "    return chain.batch(images)"
   ],
   "id": "9244fcda24c1f1c4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T07:31:27.637496Z",
     "start_time": "2025-07-27T07:31:27.629691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def extract_images(doc: fitz.Document, model: str, prompt: str, summarize: bool = True) -> list[Document]:\n",
    "    documents: list[Document] = []\n",
    "    images: list[str] = []\n",
    "    for idx, page in enumerate(doc):\n",
    "        for img in page.get_images(full=True):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)[\"image\"]\n",
    "            pil_image = Image.open(io.BytesIO(base_image))\n",
    "            file = f\"{IMAGES_FOLDER}/{idx}_{img[7]}.png\"\n",
    "            pil_image.save(file, \"PNG\")\n",
    "            documents.append(\n",
    "                Document(page_content=\"\",\n",
    "                         metadata=dict(doc.metadata, pdf=doc._name, page=page.number + 1, file=file, type=\"image\")))\n",
    "            if summarize:\n",
    "                images.append(base64.encodebytes(base_image).decode(\"ascii\"))\n",
    "    if summarize:\n",
    "        summarized_images = summarize_images(images,\n",
    "                                             prompt,\n",
    "                                             model)\n",
    "        for doc, summary in zip(documents, summarized_images):\n",
    "            doc.page_content = summary\n",
    "    return documents\n",
    "\n"
   ],
   "id": "3e7d263860ec2c06",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T07:31:27.666364Z",
     "start_time": "2025-07-27T07:31:27.658847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def extract_tables(doc: fitz.Document, model: str, prompt: str, summarize: bool = True) -> list[Document]:\n",
    "    documents: list[Document] = []\n",
    "    images: list[str] = []\n",
    "    for idx, page in enumerate(doc):\n",
    "        tabs = page.find_tables()  # detect the tables\n",
    "        for i, tab in enumerate(tabs):  # iterate over all tables\n",
    "            pix = page.get_pixmap(clip=tab.bbox)\n",
    "            file = f\"{TABLES_FOLDER}/{idx}_{i}.png\"\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            img.save(file, \"PNG\")\n",
    "            buffered = io.BytesIO()\n",
    "            img.save(buffered, format=\"PNG\")\n",
    "            documents.append(\n",
    "                Document(page_content=\"\",\n",
    "                         metadata=dict(doc.metadata, pdf=doc._name, page=page.number + 1, file=file, type=\"table\")))\n",
    "            if summarize:\n",
    "                images.append(base64.encodebytes(buffered.getvalue()).decode(\"ascii\"))\n",
    "    if summarize:\n",
    "        summarized_images = summarize_images(images, prompt, model)\n",
    "        for doc, summary in zip(documents, summarized_images):\n",
    "            doc.page_content = summary\n",
    "\n",
    "    return documents\n"
   ],
   "id": "167d6ff76f3d9b9c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T07:31:27.692782Z",
     "start_time": "2025-07-27T07:31:27.688295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def extract_text(doc: fitz.Document) -> list[Document]:\n",
    "    pages = pymupdf4llm.to_markdown(doc=doc, ignore_images=True, table_strategy=None, page_chunks=True)\n",
    "    return [Document(page_content=page['text'], metadata=dict(page['metadata'], type='text')) for page in pages]\n"
   ],
   "id": "f404644155878329",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T07:31:27.727322Z",
     "start_time": "2025-07-27T07:31:27.721446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_retriever(embeddings_model: str, chunk_size: int, chunk_overlap: int):\n",
    "    embeddings = OpenAIEmbeddings(model=embeddings_model)\n",
    "    # vector_store = Chroma(\n",
    "    #     collection_name=\"aifinals_collection\",\n",
    "    #     embedding_function=embeddings,\n",
    "    #     persist_directory=\"./storage/db\",  # Where to save data locally, remove if not necessary\n",
    "    # )\n",
    "\n",
    "    store = InMemoryStore()\n",
    "    return ParentDocumentRetriever(\n",
    "        vectorstore=InMemoryVectorStore(embeddings),\n",
    "        docstore=store,\n",
    "        child_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap),\n",
    "    )\n"
   ],
   "id": "3b6dc794dead8ecd",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T07:31:27.763226Z",
     "start_time": "2025-07-27T07:31:27.755521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_document_info(doc: fitz.Document, text_docs, image_docs, table_docs) -> dict:\n",
    "    doc_info = {}\n",
    "    doc_info[\"name\"] = doc._name\n",
    "    doc_info[\"pages_count\"] = len(doc)\n",
    "    doc_info[\"images_count\"] = len(image_docs)\n",
    "    doc_info[\"tables_count\"] = len(table_docs)\n",
    "    doc_info[\"text_length\"] = sum([len(doc.page_content) for doc in text_docs])\n",
    "    for page in range(len(doc)):\n",
    "        page_info = {}\n",
    "        page_info[\"page_number\"] = page + 1\n",
    "        page_info[\"text_length\"] = len(text_docs[page].page_content)\n",
    "        page_info[\"images_count\"] = len([document for document in image_docs if document.metadata[\"page\"] == page + 1])\n",
    "        page_info[\"tables_count\"] = len([document for document in table_docs if document.metadata[\"page\"] == page + 1])\n",
    "        doc_info[f\"page_{page + 1}\"] = page_info\n",
    "    return doc_info"
   ],
   "id": "4cb254a7afeb5584",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T07:31:27.792529Z",
     "start_time": "2025-07-27T07:31:27.786933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_retriever_from_document(doc: fitz.Document, embeddings_model: str, chunk_size, chunk_overlap,\n",
    "                                   images_summary_model, images_summary_prompt,\n",
    "                                   tables_summary_model, tables_summary_prompt):\n",
    "    retriever = create_retriever(embeddings_model, chunk_size, chunk_overlap)\n",
    "\n",
    "    text_docs = extract_text(doc)\n",
    "    image_docs = extract_images(doc, images_summary_model, images_summary_prompt)\n",
    "    table_docs = extract_tables(doc, tables_summary_model, tables_summary_prompt)\n",
    "\n",
    "    retriever.add_documents(text_docs)\n",
    "    retriever.add_documents(image_docs)\n",
    "    retriever.add_documents(table_docs)\n",
    "\n",
    "    return retriever, create_document_info(doc, text_docs, image_docs, table_docs)\n"
   ],
   "id": "543d5b3c57e351b3",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T07:32:03.716977Z",
     "start_time": "2025-07-27T07:31:27.850181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever, doc_info = create_retriever_from_document(doc, EMBEDDINGS_MODEL, CHUNK_SIZE, CHUNK_OVERLAP,\n",
    "                                                     IMAGES_SUMMARY_MODEL, IMAGES_SUMMARY_PROMPT, TABLES_SUMMARY_MODEL,\n",
    "                                                     TABLES_SUMMARY_PROMPT)"
   ],
   "id": "67751daa6f9eae4e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T07:32:03.739091Z",
     "start_time": "2025-07-27T07:32:03.733027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import gradio as gr\n",
    "#\n",
    "#\n",
    "# def recreate_db_lst(embeddings_model: str, chunk_size: int, chunk_overlap: int):\n",
    "#     global retriever\n",
    "#     global doc_info\n",
    "#     retriever = create_retriever(embeddings_model, chunk_size, chunk_overlap)\n",
    "#     doc_info = {}\n",
    "#     return \"Retriever recreated\"\n",
    "#\n",
    "#\n",
    "# def show_documents(type):\n",
    "#     documents = retriever.vectorstore.similarity_search(\"\", k=100, filter=lambda x: x.metadata[\"type\"] == type)\n",
    "#     return documents_to_markdown(documents)\n",
    "#\n",
    "#\n",
    "# def extract_images_lst(summary_model: str, summary_prompt: str):\n",
    "#     retriever.add_documents(extract_images(doc, summary_model, summary_prompt))\n",
    "#     return show_documents(\"image\")\n",
    "#\n",
    "#\n",
    "# def extract_tables_lst(summary_model: str, summary_prompt: str):\n",
    "#     retriever.add_documents(extract_tables(doc, summary_model, summary_prompt))\n",
    "#     return show_documents(\"table\")\n",
    "#\n",
    "#\n",
    "# def documents_to_markdown(documents: list[Document]) -> str:\n",
    "#     sorted_documents = sorted(documents, key=lambda x: x.metadata['page'], reverse=False)\n",
    "#     if len(sorted_documents) == 0:\n",
    "#         return \"No documents found\"\n",
    "#\n",
    "#     res = \"\"\n",
    "#\n",
    "#     for idx, document in enumerate(sorted_documents):\n",
    "#         res += f\"# {idx + 1}/{len(sorted_documents)} {document.id}\\n\"\n",
    "#         for key, value in document.metadata.items():\n",
    "#             res += f\"**{key}:** {value}\\n\"\n",
    "#         res += \"\\n\"\n",
    "#         if document.metadata['type'] == 'table' or document.metadata['type'] == 'image':\n",
    "#             with open(document.metadata[\"file\"], \"rb\") as image_file:\n",
    "#                 encoded_string = base64.b64encode(image_file.read()).decode('ascii')\n",
    "#             img = \"![](data:image/png;base64,\" + encoded_string + \")\"\n",
    "#             res += img + \"\\n\"\n",
    "#         res += document.page_content + \"\\n***\\n\"\n",
    "#     return res\n",
    "#\n",
    "#\n",
    "# def reimport_db_lst(embeddings_model: str, chunk_size, chunk_overlap, images_summary_model, images_summary_prompt,\n",
    "#                     tables_summary_model, tables_summary_prompt):\n",
    "#     global retriever\n",
    "#     global doc_info\n",
    "#     retriever, doc_info = create_retriever_from_document(doc, embeddings_model, chunk_size, chunk_overlap,\n",
    "#                                                          images_summary_model, images_summary_prompt,\n",
    "#                                                          tables_summary_model, tables_summary_prompt)\n",
    "#     return \"Document is reimported\"\n",
    "#\n",
    "#\n",
    "# def query_lst(query: str):\n",
    "#     global retriever\n",
    "#     return documents_to_markdown(retriever.invoke(query))\n",
    "#\n",
    "#\n",
    "# def handle_click(button: gr.Button, all_buttons: list[gr.Button], **kwargs) -> None:\n",
    "#     button.click(fn=lambda: tuple([gr.update(interactive=False) for b in all_buttons]), inputs=None,\n",
    "#                  outputs=all_buttons) \\\n",
    "#         .then(**kwargs) \\\n",
    "#         .then(fn=lambda: tuple([gr.update(interactive=True) for b in all_buttons]), inputs=None,\n",
    "#               outputs=all_buttons)\n",
    "#\n",
    "#\n",
    "# with (gr.Blocks() as demo):\n",
    "#     with gr.Row():\n",
    "#         with gr.Column():\n",
    "#             with gr.Row():\n",
    "#                 query = gr.Textbox(label=\"Query\")\n",
    "#             with gr.Row():\n",
    "#                 query_btn = gr.Button(\"Run query\")\n",
    "#             with gr.Row():\n",
    "#                 embeddings_model = gr.Textbox(label=\"Embeddings model\", value=EMBEDDINGS_MODEL)\n",
    "#             with gr.Row():\n",
    "#                 recreate_db_btn = gr.Button(\"Recreate Vector Storage\")\n",
    "#                 reimport_db_btn = gr.Button(\"Reimport full document\")\n",
    "#                 show_text_btn = gr.Button(\"Show text\")\n",
    "#\n",
    "#             with gr.Row():\n",
    "#                 chunk_size = gr.Number(label=\"Chunk size\", value=CHUNK_SIZE)\n",
    "#                 chunk_overlap = gr.Number(label=\"Chunk overlap\", value=CHUNK_OVERLAP)\n",
    "#             with gr.Row():\n",
    "#                 images_summary_model = gr.Textbox(label=\"Images summary model\", value=IMAGES_SUMMARY_MODEL)\n",
    "#                 images_summary_prompt = gr.Textbox(label=\"Images summary prompt\", value=IMAGES_SUMMARY_PROMPT)\n",
    "#             with gr.Row():\n",
    "#                 extract_images_btn = gr.Button(\"Import images\")\n",
    "#                 show_images_btn = gr.Button(\"Show images\")\n",
    "#             with gr.Row():\n",
    "#                 tables_summary_model = gr.Textbox(label=\"Tables summary model\", value=TABLES_SUMMARY_MODEL)\n",
    "#                 tables_summary_prompt = gr.Textbox(label=\"Tables summary prompt\", value=TABLES_SUMMARY_PROMPT)\n",
    "#             with gr.Row():\n",
    "#                 extract_tables_btn = gr.Button(\"Tables\")\n",
    "#                 show_tables_btn = gr.Button(\"Show tables\")\n",
    "#\n",
    "#         with gr.Column(min_width=300):\n",
    "#             out = gr.Markdown()\n",
    "#     buttons = [extract_images_btn, show_images_btn, recreate_db_btn, extract_tables_btn, show_tables_btn,\n",
    "#                reimport_db_btn, show_text_btn, query_btn]\n",
    "#\n",
    "#     handle_click(query_btn, buttons, fn=query_lst, inputs=query, outputs=out)\n",
    "#\n",
    "#     handle_click(recreate_db_btn, buttons, fn=recreate_db_lst, inputs=[embeddings_model, chunk_size, chunk_overlap],\n",
    "#                  outputs=out)\n",
    "#\n",
    "#     handle_click(extract_images_btn, buttons, fn=extract_images_lst,\n",
    "#                  inputs=[images_summary_model, images_summary_prompt], outputs=out)\n",
    "#     handle_click(show_images_btn, buttons, fn=lambda: show_documents(\"image\"), outputs=out)\n",
    "#\n",
    "#     handle_click(extract_tables_btn, buttons, fn=extract_tables_lst,\n",
    "#                  inputs=[tables_summary_model, tables_summary_prompt], outputs=out)\n",
    "#     handle_click(show_tables_btn, buttons, fn=lambda: show_documents(\"table\"), outputs=out)\n",
    "#\n",
    "#     handle_click(show_text_btn, buttons, fn=lambda: show_documents(\"text\"), outputs=out)\n",
    "#     handle_click(reimport_db_btn, buttons, fn=reimport_db_lst,\n",
    "#                  inputs=[embeddings_model, chunk_size, chunk_overlap, images_summary_model, images_summary_prompt,\n",
    "#                          tables_summary_model, tables_summary_prompt],\n",
    "#                  outputs=out)\n",
    "#\n",
    "#\n",
    "# #demo.launch()"
   ],
   "id": "e1ff55471a554cc9",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T07:32:03.784322Z",
     "start_time": "2025-07-27T07:32:03.778530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def retrieve_page_resource(page_number: int, type) -> list[Document]:\n",
    "    return [document for _, document in retriever.docstore.store.items() if\n",
    "            document.metadata[\"page\"] == page_number and document.metadata[\"type\"] == type]\n"
   ],
   "id": "2dc459b6840cca52",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T07:32:04.116886Z",
     "start_time": "2025-07-27T07:32:03.809446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def serialize_docs(docs: list[Document]) -> str:\n",
    "    return \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in docs\n",
    "    )\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_images_from_page(page_number: int):\n",
    "    \"\"\"Retrieve a detailed summary of images from a page.\"\"\"\n",
    "    retrieved_docs = retrieve_page_resource(page_number, \"image\")\n",
    "    serialized = serialize_docs(retrieved_docs)\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_tables_from_page(page_number: int):\n",
    "    \"\"\"Retrieve a detailed summary of tables from a page.\"\"\"\n",
    "    retrieved_docs = retrieve_page_resource(page_number, \"table\")\n",
    "    serialized = serialize_docs(retrieved_docs)\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_text_from_page(page_number: int):\n",
    "    \"\"\"Retrieve text content from a page.\"\"\"\n",
    "    retrieved_docs = retrieve_page_resource(page_number, \"text\")\n",
    "    serialized = serialize_docs(retrieved_docs)\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query from the document.\"\"\"\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "    serialized = serialize_docs(retrieved_docs)\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "\n",
    "def create_agent(llm_model, doc_info):\n",
    "    llm = init_chat_model(llm_model, model_provider=\"openai\")\n",
    "    doc_structure = json.dumps(doc_info, indent=4)\n",
    "    system_prompt = \"\"\"You are a helpful assistant capable of answering questions about the user's document. Use the appropriate tools to retrieve relevant information from the user's document. If you don't know the answer, simply state that you don't know.\n",
    "The document has the following structure:\\n\"\"\" + doc_structure\n",
    "\n",
    "    return create_react_agent(llm,\n",
    "                              [retrieve, retrieve_images_from_page, retrieve_tables_from_page, retrieve_text_from_page],\n",
    "                              prompt=system_prompt,\n",
    "                              checkpointer=MemorySaver())\n",
    "\n",
    "\n",
    "agent_executor = create_agent(LLM_MODEL, doc_info)\n",
    "display(IPython.display.Image(agent_executor.get_graph().draw_mermaid_png()))\n"
   ],
   "id": "3087f417caab8499",
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T08:13:32.076473Z",
     "start_time": "2025-07-27T08:13:27.941777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# input_message = \"Text from page 1\"\n",
    "#\n",
    "# steps3 = []\n",
    "# for step in agent_executor.stream(\n",
    "#         {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "#         stream_mode=\"values\",\n",
    "#         config={\"thread_id\": \"9\"},\n",
    "# ):\n",
    "#     steps3.append(step)\n",
    "#     step[\"messages\"][-1].pretty_print()"
   ],
   "id": "38a504bd15f1d9a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Text from page 1\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_text_from_page (call_7SVTcifOxt9h58rCmmT4AkbR)\n",
      " Call ID: call_7SVTcifOxt9h58rCmmT4AkbR\n",
      "  Args:\n",
      "    page_number: 1\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: retrieve_text_from_page\n",
      "\n",
      "Source: {'format': 'PDF 1.7', 'title': 'Exhibit99_Q4_2024', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Microsoft¬Æ Word for Microsoft 365', 'producer': 'Microsoft¬Æ Word for Microsoft 365', 'creationDate': \"D:20250724115358+03'00'\", 'modDate': \"D:20250724115358+03'00'\", 'trapped': '', 'encryption': None, 'file_path': 'EPAM-Reports-Results-for-Fourth-Quarter-and-Full-Year-2024_4.pdf', 'page_count': 15, 'page': 1, 'type': 'text'}\n",
      "Content: # **EPAM Reports Results for Fourth Quarter and Full Year 2024**\n",
      "\n",
      "_**Fourth Quarter 2024**_\n",
      "\n",
      "\n",
      " _**Revenues of $1.248 billion, up 7.9% year-over-year**_\n",
      "\n",
      " - _**GAAP Income from Operations was 10.9% of revenues and Non-GAAP Income from Operations was**_\n",
      "_**16.7% of revenues**_\n",
      "\n",
      " _**GAAP Diluted EPS of $1.80, an increase of 8.4%, and Non-GAAP Diluted EPS of $2.84, an increase of**_\n",
      "_**3.3% on a year-over-year basis**_\n",
      "\n",
      "\n",
      "_**Full Year 2024**_\n",
      "\n",
      "\n",
      " _**Revenues of $4.728 billion, up 0.8% year-over-year**_\n",
      "\n",
      " - _**GAAP Income from Operations was 11.5% of revenues and Non-GAAP Income from Operations was**_\n",
      "_**16.5% of revenues**_\n",
      "\n",
      " _**GAAP Diluted EPS of $7.84, an increase of 11.0%, and Non-GAAP Diluted EPS of $10.86, an increase of**_\n",
      "_**2.5% on a year-over-year basis**_\n",
      "\n",
      "\n",
      "Newtown, PA, USA, February 20, 2025 ‚Äî EPAM Systems, Inc. (NYSE: EPAM), a leading digital transformation services and\n",
      "product engineering company, today announced results for its fourth quarter and full year ended December 31, 2024.\n",
      "\n",
      "\n",
      "‚ÄúAfter navigating a dynamic year, we are pleased to report a strong fourth quarter. We continued to build sequential\n",
      "momentum, and saw a return to year-over-year organic growth, while we simultaneously accelerated our global strategy\n",
      "with the acquisitions of NEORIS and First Derivative,‚Äù said Arkadiy Dobkin, CEO & President, EPAM. ‚ÄúAs we look ahead,\n",
      "we believe 2025 will be a year of transition, as clients balance their cost focus with the need to accelerate their\n",
      "transformational and GenAI journeys. We see a strong need to continue to invest in our talent, advanced technological\n",
      "and consulting capabilities, and the integration of recent acquisitions to best position ourselves to capture market share\n",
      "once demand returns to more normalized levels.‚Äù\n",
      "\n",
      "\n",
      "**Fourth Quarter 2024 Highlights**\n",
      "\n",
      "\n",
      " - Revenues increased to $1.248 billion, a year-over-year increase of $91.1 million, or 7.9%. On an organic constant\n",
      "\n",
      "currency basis, revenues grew 1.0% compared to the fourth quarter of 2023;\n",
      "\n",
      "\n",
      " - GAAP income from operations was $136.5 million, an increase of $14.0 million, or 11.4%, compared to $122.5\n",
      "\n",
      "million in the fourth quarter of 2023;\n",
      "\n",
      "\n",
      " - Non-GAAP income from operations was $208.2 million, an increase of $7.8 million, or 3.9%, compared to $200.4\n",
      "\n",
      "million in the fourth quarter of 2023;\n",
      "\n",
      "\n",
      " - Diluted earnings per share (‚ÄúEPS‚Äù) on a GAAP basis was $1.80, an increase of $0.14, or 8.4%, compared to $1.66 in\n",
      "\n",
      "the fourth quarter of 2023;\n",
      "\n",
      "\n",
      " - Non-GAAP diluted EPS was $2.84, an increase of $0.09, or 3.3%, compared to $2.75 in the fourth quarter of 2023;\n",
      "\n",
      "\n",
      " - Completed the acquisition of NEORIS creating a competitive offering for clients across Latin America and in\n",
      "\n",
      "Spanish- and Portuguese-speaking countries, while broadening EPAM's global and nearshore delivery capabilities\n",
      "across Latin America and Europe; and\n",
      "\n",
      "\n",
      " - Completed the acquisition of First Derivative strengthening EPAM's financial services consulting and delivery\n",
      "\n",
      "capabilities in North America, Europe and APAC and expanding our client portfolio in financial services.\n",
      "\n",
      "\n",
      "\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Here is the text from page 1 of the document:\n",
      "\n",
      "EPAM Systems, Inc. (NYSE: EPAM) announced their financial results for the fourth quarter and full year ended December 31, 2024:\n",
      "\n",
      "**Fourth Quarter 2024:**\n",
      "- Revenues: $1.248 billion, up 7.9% year-over-year\n",
      "- GAAP Income from Operations: 10.9% of revenues\n",
      "- Non-GAAP Income from Operations: 16.7% of revenues\n",
      "- GAAP Diluted EPS: $1.80, an increase of 8.4%\n",
      "- Non-GAAP Diluted EPS: $2.84, an increase of 3.3%\n",
      "\n",
      "**Full Year 2024:**\n",
      "- Revenues: $4.728 billion, up 0.8% year-over-year\n",
      "- GAAP Income from Operations: 11.5% of revenues\n",
      "- Non-GAAP Income from Operations: 16.5% of revenues\n",
      "- GAAP Diluted EPS: $7.84, an increase of 11.0%\n",
      "- Non-GAAP Diluted EPS: $10.86, an increase of 2.5%\n",
      "\n",
      "The company highlighted strategic acquisitions of NEORIS and First Derivative to enhance its global and financial services capabilities. CEO Arkadiy Dobkin noted the challenging year and expected 2025 to be a transitional year driven by client demand for digital transformation and GenAI integration.\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T08:32:44.114491Z",
     "start_time": "2025-07-27T08:31:48.739195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gradio as gr\n",
    "from datetime import datetime\n",
    "\n",
    "config = None\n",
    "\n",
    "\n",
    "def recreate_config():\n",
    "    global config\n",
    "    config = {\"thread_id\": datetime.now().strftime(\"%H:%M:%S\")}\n",
    "\n",
    "\n",
    "recreate_config()\n",
    "\n",
    "\n",
    "def user(user_message, history: list):\n",
    "    return \"\", history + [{\"role\": \"user\", \"content\": user_message}]\n",
    "\n",
    "\n",
    "def bot(history: list):\n",
    "    global last_artifact\n",
    "    user_msg = history[-1][\"content\"]\n",
    "\n",
    "    for step in agent_executor.stream(\n",
    "            {\"messages\": [{\"role\": \"user\", \"content\": user_msg}]},\n",
    "            stream_mode=\"values\",\n",
    "            config=config,\n",
    "    ):\n",
    "        messages = step[\"messages\"][1:]\n",
    "        new_messages = []\n",
    "        for message in messages:\n",
    "            if message.type == \"human\":\n",
    "                new_messages.append(gr.ChatMessage(role=\"user\", content=message.content))\n",
    "            elif message.type == \"ai\":\n",
    "                if len(message.tool_calls) > 0:\n",
    "                    for tool_call in message.tool_calls:\n",
    "                        new_messages.append(gr.ChatMessage(role=\"assistant\",\n",
    "                                                           content=f\"I need to use the **{tool_call[\"name\"]}** tool with arguments **{tool_call[\"args\"]}**.\",\n",
    "                                                           metadata={\"title\": \"üß† Thinking\"}))\n",
    "                else:\n",
    "                    new_messages.append(gr.ChatMessage(role=\"assistant\", content=message.content))\n",
    "            elif message.type == \"tool\":\n",
    "                new_messages.append(gr.ChatMessage(role=\"assistant\", content=message.content[:15] + \"...\",\n",
    "                                                   metadata={\"title\": f\"üõ†Ô∏è Used tool **{message.name}**\",\n",
    "                                                             \"id\": message.tool_call_id}))\n",
    "                for artifact in message.artifact:\n",
    "                    metadata = None\n",
    "                    if type(artifact) is dict:\n",
    "                        metadata = artifact[\"metadata\"]\n",
    "                    else:\n",
    "                        metadata = artifact.metadata\n",
    "                    if \"file\" in metadata:\n",
    "                        new_messages.append(\n",
    "                            gr.ChatMessage(role=\"assistant\", content=gr.Image(value=metadata[\"file\"]),\n",
    "                                           metadata={\"title\": metadata[\"file\"]}))\n",
    "                    else:\n",
    "                        new_messages.append(gr.ChatMessage(role=\"assistant\", content=artifact.page_content,\n",
    "                                                           metadata={\"parent_id\": message.tool_call_id}))\n",
    "            #print(new_messages)\n",
    "            yield [history[0]] + new_messages\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(type=\"messages\")\n",
    "    msg = gr.Textbox()\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    chatbot.clear(recreate_config)\n",
    "\n",
    "demo.launch(debug=True, height=600)"
   ],
   "id": "925a1025526e9fff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"600\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
